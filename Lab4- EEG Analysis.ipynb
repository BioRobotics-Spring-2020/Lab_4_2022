{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4\n",
    "\n",
    "Introduction to  EEG Analysis. This notebook is for you to get exposure to EEG signal analysis and artifact removal.\n",
    "\n",
    "## EEG Theory\n",
    "\n",
    "### Eletroencephalography\n",
    "\n",
    "The electroencephalogram or EEG is a recording of the biopotentials in the cerebrum of thebrain. These potentials are typical recorded at the surface of the scalp and can vary withrespect to the emotional, mental, and physiological state of a person. The action potentialsand synaptic potentials of an individual neurons are too small to be measured by electrodes.Therefore, an EEG is a measurement of the summation of the electrical signals produce byneurons in a defined area and over a specific amount of time. It is important to note that theseneurons need not synchronized but may be producing signals in an asynchronous manner.EEG signals can be categorizedby the four major frequency ranges or brainwaves in whichthey occur: alpha, beta, delta and theta. The corresponding frequencies, amplitudes, andtypical human functionality of the waves are seen in Table.\n",
    "\n",
    "\n",
    "| Brainwave | Frequency | Amplitude (uV) | Human Function |\n",
    "| --------- | --------- | -------------- | -------------- |\n",
    "| alpha | 8 - 13 | 2 - 100 | Awake, Quiet, Resting, Eyes Open|\n",
    "| beta | 13 - 22 | 5 - 100 | Mental Activity or External Stimulus|\n",
    "| delta | 0.4 - 4 | 20 - 100| Sleep |\n",
    "| theta | 4 - 8 | 10 | Emotional Stress | \n",
    "\n",
    "\n",
    "A special system of electrode placement called the 10-20 system is used during EEG recordings.The 10 and 20 refer to percent distances of the electrodes from each other with respect to the sizeof the patientâ€™s head. The letters F, T, C, P, and O in the 10 20 system refer to frontal, temporal,central, parietal, and occipital or essential lobes of the brain excluding central. Also, even numbers are located on the right hemisphere and odd numbers on the left hemisphere. The letterz is an indicator of the central line of the head.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''You will need to install the following package'''\n",
    "!pip3 install fooof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the CSV\n",
    "We first need to read in the csv file name from your data. Please insert the name of your file in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mne\n",
    "import os\n",
    "import scipy\n",
    "# Opens up another window with your plot\n",
    "%matplotlib qt \n",
    "# Read in Data\n",
    "directory = 'Lab_4_Data'\n",
    "participant = ...\n",
    "file = ...\n",
    "EEGCsv = pd.read_csv(os.path.join(directory, participant, file))\n",
    "EEGCsv.index = pd.to_datetime(EEGCsv['timestamps'], unit='s')\n",
    "\n",
    "# Set channel sampling frequency\n",
    "fs = 250\n",
    "seconds = EEGCsv.timestamps- EEGCsv.timestamps.iloc[0]\n",
    "\n",
    "ch_names = [ 'Fz', 'C3', 'Cz', 'C4', 'Pz', 'PO7', 'Oz', 'PO8'] # set EEG channel names\n",
    "for ch in [ 'Fz', 'C3', 'Cz', 'C4', 'Pz', 'PO7', 'Oz', 'PO8']:\n",
    "    EEGCsv[ch] = EEGCsv[ch]/100000 # rescale data (uv to volts)\n",
    "    EEGCsv[ch] = mne.filter.filter_data(EEGCsv[ch].values, 250, 0.1, 100) # apply a highpass filter\n",
    "    EEGCsv[ch] = mne.baseline.rescale(EEGCsv[ch].values, seconds, (0,10)) # apply baseline rescaling\n",
    "    \n",
    "\n",
    "\n",
    "display(EEGCsv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## EEG Signals\n",
    "The above code prints out a table containing your collected data. One thing to note is the column names and what they correspond to. We have time, electrode position values, and Stim (0 or 1). For now, lets focus on the electrode positions.\n",
    "\n",
    "The data was collected using the standard 10-20 placement. The code below shows you these positions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mon = mne.channels.make_standard_montage('standard_1020')\n",
    "mon.plot(kind='topomap', show_names=True)# 2d Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The window that this opens is interactable, so you can rotate around to get a better idea where each electrode is.\n",
    "mon.plot(kind='3d', show_names=True)# 3d Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "We now need to plot signals from our dataset. Unfortunately, some of the electrode positions are incorrectly named and need to be renamed. Our analysis uses the MNE toolbox. Feel free to look at the MNE documentation online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create MNE Info to apply to csv data\n",
    "info = mne.create_info(ch_names, fs, ch_types='eeg')\n",
    "\n",
    "df_mne = EEGCsv[ch_names]\n",
    "\n",
    "# Create the Raw Object for MNE\n",
    "raw = mne.io.RawArray(df_mne.values.transpose(), info)\n",
    "\n",
    "\n",
    "# Plot the data\n",
    "raw.plot(n_channels=8)\n",
    "\n",
    "'''You can scale the graphs using +/-'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_psd(area_mode='range', tmax=10.0, show=False, average=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notch Filter\n",
    "\n",
    "You should see a spike in the PSD ~60. The code below will apply a notch filter at 60 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.fftpack\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Run the following to create a notch filter at 60 hz and view the resulting PSD\n",
    "raw.notch_filter(np.arange(60, 128, 60))\n",
    "raw.plot_psd(area_mode='range', tmax=10.0, show=False, average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nans(data, nan_policy='zero'):\n",
    "    \"\"\"Check an array for nan values, and replace, based on policy.\"\"\"\n",
    "\n",
    "    # Find where there are nan values in the data\n",
    "    nan_inds = np.where(np.isnan(data))\n",
    "\n",
    "    # Apply desired nan policy to data\n",
    "    if nan_policy == 'zero':\n",
    "        data[nan_inds] = 0\n",
    "    elif nan_policy == 'mean':\n",
    "        data[nan_inds] = np.nanmean(data)\n",
    "    else:\n",
    "        raise ValueError('Nan policy not understood.')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mne.viz import plot_topomap\n",
    "from mne.time_frequency import psd_welch\n",
    "\n",
    "# FOOOF imports\n",
    "from fooof import FOOOFGroup\n",
    "from fooof.bands import Bands\n",
    "from fooof.analysis import get_band_peak_fg\n",
    "from fooof.plts.spectra import plot_spectrum\n",
    "\n",
    "from matplotlib import cm, colors, colorbar\n",
    "\n",
    "'''Set the 10-20 montage for our data'''\n",
    "raw.set_montage(mon)\n",
    "\n",
    "'''Apply the PSD Welch algorithm to get the Power Spectral Density'''\n",
    "spectra, freqs = psd_welch(raw, fmin=1, fmax=40, tmin=0, tmax=250,\n",
    "                           n_overlap=150, n_fft=250)\n",
    "\n",
    "# Initialize a FOOOFGroup object, with desired settings\n",
    "fg = FOOOFGroup(peak_width_limits=[1, 6], min_peak_height=0.15,\n",
    "                peak_threshold=2., max_n_peaks=6, verbose=False)\n",
    "\n",
    "# Define the frequency range to fit\n",
    "freq_range = [1, 30]\n",
    "\n",
    "# Fit the power spectrum model across all channels\n",
    "fg.fit(freqs, spectra, freq_range)\n",
    "\n",
    "# Define frequency bands of interest\n",
    "bands = Bands({'theta': [3, 7],\n",
    "               'alpha': [7, 14],\n",
    "               'beta': [15, 30]})\n",
    "\n",
    "# Extract alpha peaks\n",
    "alphas = get_band_peak_fg(fg, bands.alpha)\n",
    "\n",
    "# Extract the power values from the detected peaks\n",
    "alpha_pw = alphas[:, 1]\n",
    "\n",
    "# We need to remove nans for the plot to show\n",
    "alpha_pw = check_nans(alpha_pw) \n",
    "\n",
    "# Plot the topography of alpha power\n",
    "plot_topomap(alpha_pw, raw.info, cmap=cm.viridis, contours=0);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "for ind, (label, band_def) in enumerate(bands):\n",
    "\n",
    "    # Get the power values across channels for the current band\n",
    "    band_power = check_nans(get_band_peak_fg(fg, band_def)[:, 1])\n",
    "\n",
    "    # Extracted and plot the power spectrum model with the most band power\n",
    "    fg.get_fooof(np.argmax(band_power)).plot(ax=axes[ind], add_legend=False)\n",
    "\n",
    "    # Set some plot aesthetics & plot title\n",
    "    axes[ind].yaxis.set_ticklabels([])\n",
    "    axes[ind].set_title('Largest ' + label + ' peak', {'fontsize' : 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Related Potentials\n",
    "\n",
    "Now that we have an idea of how to extract some meaningful information from EEG signals, we need to do some analysis specifically with our dataset. \n",
    "\n",
    "Cats and dogs flashed on the screen. The participant is looking for a specific stimulus, hence the 'stim' column. These stimuli produce what is called a P300 Event Related Potential. We are going to analyze these potentials between the target and non target stimuli.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We are going to go back to the original dataset and use the Pandas Groupby method to figure out when the target events occur\n",
    "EEGCsv.groupby('stim').get_group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "# We can now compare an ERP between a target and non-target event.\n",
    "# We need to slice our dataframe to get the P300 timeframe from these events.\n",
    "# P300 events occur when a positive deflection occurs approx 300 msec after a triggering event (stimulus)\n",
    "# Lets see if we can find this peak visually\n",
    "\n",
    "# We first find a target time by using the .iloc method\n",
    "TargetTime = EEGCsv.groupby('stim').get_group(1).index[0]\n",
    "\n",
    "# Then we can index the TimeFrame for the P300\n",
    "StartTime = TargetTime - dt.timedelta(200*0.001) # Starting at -200 msec\n",
    "EndTime   = TargetTime + dt.timedelta(500*0.001) # Ending at 500 msec\n",
    "\n",
    "ERPdf = EEGCsv[(EEGCsv.index > StartTime) & (EEGCsv.index < EndTime)]\n",
    "\n",
    "# Lets look at what the raw data looks like for 1 ERP\n",
    "display(ERPdf)\n",
    "\n",
    "# This code will be useful for the lab questions when computing the PSD of the ERPs. The next code sections are better for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNE Library and ERPs\n",
    "We first need to drop columns from our raw data that are not EEG based. Then we can scale and create a raw MNE array for easy plotting.\n",
    "\n",
    "The next step creates Event Info from our Event column in the original array. We can then use MNE functionality to plot the ERPs between target and non-target events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create MNE Info to apply to csv data\n",
    "info = mne.create_info(ch_names, fs, ch_types='eeg')\n",
    "info['chs'][-1]['kind']\n",
    "\n",
    "\n",
    "\n",
    "# Create Raw Array\n",
    "raw = mne.io.RawArray(df_mne.transpose(), info)\n",
    "\n",
    "\n",
    "# Create Event info and add to raw array\n",
    "info = mne.create_info(['STI 0'], raw.info['sfreq'], ['stim'])\n",
    "temp = EEGCsv['stim'].values\n",
    "temp = np.reshape(temp, (1, -1))\n",
    "stim_raw = mne.io.RawArray(temp, info)\n",
    "raw.add_channels([stim_raw], force_update_info=True)\n",
    "\n",
    "# Get events object for easy access\n",
    "events = mne.find_events(raw, stim_channel='STI 0', verbose=True)\n",
    "\n",
    "display(events)\n",
    "\n",
    "# Plot the data\n",
    "raw.plot(events = events, n_channels=8)\n",
    "\n",
    "# Note the vertical lines indicating events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set epoch length to -0.2 seconds before stimulus and 0.5 after stimulus\n",
    "tmin, tmax = -0.2, 0.5\n",
    "\n",
    "# Set the epoch parameters based on the events in the raw data\n",
    "epochs_params = dict(events=events, event_id=, tmin=tmin, tmax=tmax)\n",
    "\n",
    "# Now we parse our data based on the target events and take the average of all channels\n",
    "epochs = mne.Epochs(raw, **epochs_params).average()\n",
    "# Set montage to 10-20\n",
    "epochs.set_montage(mon)\n",
    "# Plot EEG data and a topomap\n",
    "display(epochs.plot())\n",
    "epochs.plot_topomap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can do this for our dog pictures as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set epoch length to -0.2 seconds before stimulus and 0.5 after stimulus\n",
    "tmin, tmax = -0.2, 0.5\n",
    "\n",
    "\n",
    "# Set the epoch parameters based on the events in the raw data\n",
    "epochs_params = dict(events=events, event_id=2, tmin=tmin, tmax=tmax)\n",
    "\n",
    "# Now we parse our data based on the target events and take the average of all channels\n",
    "epochs = mne.Epochs(raw, **epochs_params).average()\n",
    "# Set montage to 10-20\n",
    "epochs.set_montage(mon)\n",
    "# Plot EEG data and a topomap\n",
    "display(epochs.plot())\n",
    "epochs.plot_topomap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two plots for target and non-target events. Note the difference between the two graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "The above code allows you to get a feel for some EEG analysis for ERPs. Please use the code above as reference to complete the following:\n",
    "\n",
    "### All data analysis\n",
    "The following should be applied to all of your collected data from the Cats and Dog experiment.\n",
    "1. Apply a notch filter\n",
    "2. Compute the average Alpha, Beta, and Theta Power\n",
    "3. Plot the topomaps for each band (Alpha, Beta, and Theta)\n",
    "\n",
    "### Target and Non Target data analysis\n",
    "For each participant\n",
    "1. Use the notch filtered Raw data from above\n",
    "2. Compute the average Alpha, Beta, and Theta PSDs for the dog and cat events\n",
    "3. Plot the Raw Averaged Epoched data for the dog and cat events\n",
    "4. Plot a Topomap for the Raw Averaged Epoched Data for the dog and cat events\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
