{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1\n",
    "\n",
    "Introduction to Labstream and EEG Analysis. This notebook is for you to get exposure to EEG signal analysis and artifact removal.\n",
    "\n",
    "## EEG Theory\n",
    "\n",
    "### Eletroencephalography\n",
    "\n",
    "The electroencephalogram or EEG is a recording of the biopotentials in the cerebrum of thebrain. These potentials are typical recorded at the surface of the scalp and can vary withrespect to the emotional, mental, and physiological state of a person. The action potentialsand synaptic potentials of an individual neurons are too small to be measured by electrodes.Therefore, an EEG is a measurement of the summation of the electrical signals produce byneurons in a defined area and over a specific amount of time. It is important to note that theseneurons need not synchronized but may be producing signals in an asynchronous manner.EEG signals can be categorizedby the four major frequency ranges or brainwaves in whichthey occur: alpha, beta, delta and theta. The corresponding frequencies, amplitudes, andtypical human functionality of the waves are seen in Table.\n",
    "\n",
    "\n",
    "| Brainwave | Frequency | Amplitude (uV) | Human Function |\n",
    "| --------- | --------- | -------------- | -------------- |\n",
    "| alpha | 8 - 13 | 2 - 100 | Awake, Quiet, Resting, Eyes Open|\n",
    "| beta | 13 - 22 | 5 - 100 | Mental Activity or External Stimulus|\n",
    "| delta | 0.4 - 4 | 20 - 100| Sleep |\n",
    "| theta | 4 - 8 | 10 | Emotional Stress | \n",
    "\n",
    "\n",
    "A special system of electrode placement called the 10-20 system is used during EEG recordings.The 10 and 20 refer to percent distances of the electrodes from each other with respect to the sizeof the patientâ€™s head. The letters F, T, C, P, and O in the 10 20 system refer to frontal, temporal,central, parietal, and occipital or essential lobes of the brain excluding central. Also, even numbers are located on the right hemisphere and odd numbers on the left hemisphere. The letterz is an indicator of the central line of the head.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the CSV\n",
    "We first need to read in the csv file name from your data. Please insert the name of your file in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mne\n",
    "# Opens up another window with your plot\n",
    "%matplotlib qt \n",
    "# Read in Data\n",
    "EEGCsv = pd.read_csv('Saved_Data/Your_File_name.csv')\n",
    "EEGCsv = EEGCsv.drop(columns=['Timestamp','Device_Time'])\n",
    "\n",
    "# Set channel sampling frequency\n",
    "fs = 512 \n",
    "display(EEGCsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## EEG Signals\n",
    "The above code prints out a table containing your collected data. One thing to note is the column names and what they correspond to. We have time, electrode position values, and Event/ IsTarget. For now, lets focus on the electrode positions.\n",
    "\n",
    "The data was collected using the standard 10-20 placement. The code below shows you these positions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mon = mne.channels.make_standard_montage('standard_1020')\n",
    "mon.plot(kind='topomap', show_names=True)# 2d Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The window that this opens is interactable, so you can rotate around to get a better idea where each electrode is.\n",
    "mon.plot(kind='3d', show_names=True)# 3d Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "We now need to plot signals from our dataset. Unfortunately, some of the electrode positions are incorrectly named and need to be renamed. Our analysis uses the MNE toolbox. Feel free to look at the MNE documentation online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Unused Columns\n",
    "df_mne = EEGCsv.drop(columns=['Time', 'Event', 'IsTarget', 'IsNonTarget', 'IsStartOfNewBlock', 'EndOfRepetitionNumber'])\n",
    "# Rename Channels\n",
    "ch_names = list(df_mne.columns)\n",
    "ch_names[2] = 'FC5'\n",
    "ch_names[4] = 'FC6'\n",
    "display(df_mne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MNE Info to apply to csv data\n",
    "info = mne.create_info(ch_names, fs, ch_types='eeg')\n",
    "\n",
    "# Create the Raw Object for MNE\n",
    "raw = mne.io.RawArray(df_mne.values.transpose(), info)\n",
    "\n",
    "# Plot the data\n",
    "raw.plot(n_channels=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should of gotten a very messy plot, but can scale the image using +/- buttons. Lets fix this\n",
    "\n",
    "# We can also apply a function to an entire pandas dataframe using the .apply method, which returns a dataframe\n",
    "# The lambda keyword creates a onetime function definition with input x. X in this case is each cell value.\n",
    "\n",
    "df_mne_scaled = df_mne.apply(lambda x: x/1000000)\n",
    "display(df_mne_scaled)\n",
    "\n",
    "# Create the Raw Object for MNE\n",
    "raw = mne.io.RawArray(df_mne_scaled.values.transpose(), info)\n",
    "\n",
    "# Plot the data\n",
    "raw.plot(n_channels=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_psd(area_mode='range', tmax=10.0, show=False, average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.fftpack\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Run the following to create a notch filter at 50 hz and view the resulting PSD\n",
    "raw.notch_filter(np.arange(50, 251, 50))\n",
    "raw.plot_psd(area_mode='range', tmax=10.0, show=False, average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mne.viz import plot_topomap\n",
    "from mne.time_frequency import psd_welch\n",
    "\n",
    "# FOOOF imports\n",
    "from fooof import FOOOFGroup\n",
    "from fooof.bands import Bands\n",
    "from fooof.analysis import get_band_peak_fg\n",
    "from fooof.plts.spectra import plot_spectrum\n",
    "\n",
    "from matplotlib import cm, colors, colorbar\n",
    "\n",
    "raw.set_montage(mon)\n",
    "\n",
    "spectra, freqs = psd_welch(raw, fmin=1, fmax=40, tmin=0, tmax=250,\n",
    "                           n_overlap=150, n_fft=512)\n",
    "\n",
    "# Initialize a FOOOFGroup object, with desired settings\n",
    "fg = FOOOFGroup(peak_width_limits=[1, 6], min_peak_height=0.15,\n",
    "                peak_threshold=2., max_n_peaks=6, verbose=False)\n",
    "\n",
    "# Define the frequency range to fit\n",
    "freq_range = [1, 30]\n",
    "\n",
    "# Fit the power spectrum model across all channels\n",
    "fg.fit(freqs, spectra, freq_range)\n",
    "\n",
    "# Define frequency bands of interest\n",
    "bands = Bands({'theta': [3, 7],\n",
    "               'alpha': [7, 14],\n",
    "               'beta': [15, 30]})\n",
    "\n",
    "# Extract alpha peaks\n",
    "alphas = get_band_peak_fg(fg, bands.alpha)\n",
    "\n",
    "# Extract the power values from the detected peaks\n",
    "alpha_pw = alphas[:, 1]\n",
    "\n",
    "# Plot the topography of alpha power\n",
    "plot_topomap(alpha_pw, raw.info, cmap=cm.viridis, contours=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, lets check the power spectra for the largest detected peaks within each band.\n",
    "\n",
    "def check_nans(data, nan_policy='zero'):\n",
    "    \"\"\"Check an array for nan values, and replace, based on policy.\"\"\"\n",
    "\n",
    "    # Find where there are nan values in the data\n",
    "    nan_inds = np.where(np.isnan(data))\n",
    "\n",
    "    # Apply desired nan policy to data\n",
    "    if nan_policy == 'zero':\n",
    "        data[nan_inds] = 0\n",
    "    elif nan_policy == 'mean':\n",
    "        data[nan_inds] = np.nanmean(data)\n",
    "    else:\n",
    "        raise ValueError('Nan policy not understood.')\n",
    "\n",
    "    return data\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "for ind, (label, band_def) in enumerate(bands):\n",
    "\n",
    "    # Get the power values across channels for the current band\n",
    "    band_power = check_nans(get_band_peak_fg(fg, band_def)[:, 1])\n",
    "\n",
    "    # Extracted and plot the power spectrum model with the most band power\n",
    "    fg.get_fooof(np.argmax(band_power)).plot(ax=axes[ind], add_legend=False)\n",
    "\n",
    "    # Set some plot aesthetics & plot title\n",
    "    axes[ind].yaxis.set_ticklabels([])\n",
    "    axes[ind].set_title('Largest ' + label + ' peak', {'fontsize' : 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Related Potentials\n",
    "\n",
    "Now that we have an idea of how to extract some meaningful information from EEG signals, we need to do some analysis specifically with our dataset. This dataset is part of this [paper](https://hal.archives-ouvertes.fr/hal-02078533v3/document)\n",
    "\n",
    "Going through this paper, you see that there are symbols that flash on screen. The participant is looking for a specific target symbol, hence the 'IsTarget' and 'IsNonTarget'. These stimulus produce what is called a P300 Event Related Potential. We are going to analyze these potentials between the target and non target stimulus.\n",
    "\n",
    "Each Event has an event number indicating what occured, such as a target symbol displaying at a specific location on screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We are going to go back to the original dataset and use the Pandas Groupby method to figure out when the target events occur\n",
    "EEGCsv.groupby('IsTarget').get_group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# No for the non-target events\n",
    "EEGCsv.groupby('IsNonTarget').get_group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We can now compare an ERP between a target and non-target event.\n",
    "# We need to slice our dataframe to get the P300 timeframe from these events.\n",
    "# P300 events occur when a positive deflection occurs approx 300 msec after a triggering event (stimulus)\n",
    "# Lets see if we can find this peak visually\n",
    "\n",
    "# We first find a target time by using the .iloc method\n",
    "TargetTime = EEGCsv.groupby('IsTarget').get_group(1).iloc[0].Time\n",
    "\n",
    "# Then we can index the TimeFrame for the P300\n",
    "StartTime = TargetTime - 200*0.001 # Starting at -200 msec\n",
    "EndTime   = TargetTime + 500*0.001 # Ending at 500 msec\n",
    "\n",
    "ERPdf = EEGCsv[(EEGCsv['Time'] > StartTime) & (EEGCsv['Time'] < EndTime)]\n",
    "\n",
    "# Lets look at what the raw data looks like for 1 ERP\n",
    "display(ERPdf)\n",
    "\n",
    "# This code will be useful for the lab questions when computing the PSD of the ERPs. The next code sections are better for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNE Library and ERPs\n",
    "We first need to drop columns from our raw data that are not EEG based. Then we can scale and create a raw MNE array for easy plotting.\n",
    "\n",
    "The next step creates Event Info from our Event column in the original array. We can then use MNE functionality to plot the ERPs between target and non-target events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Drop Non-EEG Columns\n",
    "df_mne = EEGCsv.drop(columns=['Time','Event', 'IsTarget','IsNonTarget', 'IsStartOfNewBlock', 'EndOfRepetitionNumber'])\n",
    "non_eeg_cols = ['Time','IsTarget', 'IsNonTarget', 'IsStartOfNewBlock', 'EndOfRepetitionNumber']\n",
    "# Rename Channels\n",
    "ch_names = list(df_mne.columns)\n",
    "ch_names[2] = 'FC5'\n",
    "ch_names[4] = 'FC6'\n",
    "\n",
    "# Create MNE Info to apply to csv data\n",
    "info = mne.create_info(ch_names, fs, ch_types='eeg')\n",
    "info['chs'][-1]['kind']\n",
    "\n",
    "# Rescale data\n",
    "df_mne = df_mne.apply(lambda x: x/10000000)\n",
    "\n",
    "# Create Raw Array\n",
    "raw = mne.io.RawArray(df_mne.transpose(), info)\n",
    "\n",
    "\n",
    "# Create Event info and add to raw array\n",
    "info = mne.create_info(['STI 0'], raw.info['sfreq'], ['stim'])\n",
    "temp = EEGCsv['Event'].values.transpose()\n",
    "temp = np.reshape(temp, (1, -1))\n",
    "stim_raw = mne.io.RawArray(temp, info)\n",
    "raw.add_channels([stim_raw], force_update_info=True)\n",
    "\n",
    "# Get events object for easy access\n",
    "events = mne.find_events(raw, stim_channel='STI 0', verbose=True)\n",
    "\n",
    "\n",
    "# Plot the data\n",
    "raw.plot(events = events, n_channels=16)\n",
    "\n",
    "# Note the vertical lines indicating events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add reject threshold for EEG signals\n",
    "reject = dict(eeg=180e-6)\n",
    "\n",
    "# Set epoch length to -0.2 seconds before stimulus and 0.5 after stimulus\n",
    "tmin, tmax = -0.2, 0.5\n",
    "\n",
    "# Get the Target Event values using the Pandas groupby method\n",
    "targets = EEGCsv.groupby('IsTarget').get_group(1).Event.values\n",
    "display(targets)\n",
    "\n",
    "# Set the epoch parameters based on the events in the raw data, the first event Id (65)\n",
    "epochs_params = dict(events=events, event_id=int(targets[0]), tmin=tmin, tmax=tmax,\n",
    "                     reject=reject)\n",
    "\n",
    "# Now we parse our data based on the target events and take the average of all channels\n",
    "epochs = mne.Epochs(raw, **epochs_params).average()\n",
    "# Set montage to 10-20\n",
    "epochs.set_montage(mon)\n",
    "# Plot EEG data and a topomap\n",
    "display(epochs.plot())\n",
    "epochs.plot_topomap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do the same for the non target events\n",
    "nontargets = EEGCsv.groupby('IsNonTarget').get_group(1).Event.values\n",
    "display(nontargets)\n",
    "epochs_params = dict(events=events, event_id=int(nontargets[0]), tmin=tmin, tmax=tmax,\n",
    "                     reject=reject)\n",
    "epochs = mne.Epochs(raw, **epochs_params).average()\n",
    "epochs.set_montage(mon)\n",
    "display(epochs.plot())\n",
    "epochs.plot_topomap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two plots for target and non-target events. Note the difference between the two graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "The above code allows you to get a feel for some EEG analysis for ERPs. Please use the code above as reference to complete the following:\n",
    "\n",
    "### All data analysis\n",
    "The following should be applied to all of your collected data\n",
    "1. Apply a notch filter\n",
    "2. Compute the average Alpha, Beta, and Theta Power\n",
    "3. Plot the topomaps for each band (Alpha, Beta, and Theta\n",
    "\n",
    "### Target and Non Target data analysis\n",
    "Choose a target event id and a non-target event id that is different from the ids above.\n",
    "\n",
    "1. Use the notch filtered Raw data from above\n",
    "2. Compute the average Alpha, Beta, and Theta PSDs for the target and non target event\n",
    "3. Plot the Raw Averaged Epoched data for the target and non-target event\n",
    "4. Plot a Topomap for the Raw Averaged Epoched Data for the target and non-target event\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
